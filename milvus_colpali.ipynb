{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/cp_ft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import ColQwen2ForRetrieval, ColQwen2Processor\n",
    "from colpali_engine.utils.torch_utils import ListDataset, get_torch_device\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "from typing import List, cast\n",
    "\n",
    "device = get_torch_device(\"auto\")\n",
    "\n",
    "# Load tokenizer and base model\n",
    "base_model_path = \"/home/linux/yyj/colpali/finetune/colqwen2-v1.0-hf\"\n",
    "base_model = ColQwen2ForRetrieval.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ").eval()\n",
    "# Load fine-tuned adapter (LoRA weights)\n",
    "adapter_path = \"/home/linux/yyj/colpali/finetune/wiky_city_zh_0702_lr2e4_colqwen\"\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "max_pixels = 1100*28*28\n",
    "processor = ColQwen2Processor.from_pretrained(adapter_path, max_pixels=max_pixels)\n",
    "\n",
    "queries = [\n",
    "    \"阿布达比5月气温怎么样\",\n",
    "    \"阿布达比12月降水量怎么样\",\n",
    "]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=ListDataset[str](queries),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: processor.process_queries(x),\n",
    ")\n",
    "\n",
    "qs: List[torch.Tensor] = []\n",
    "for batch_query in dataloader:\n",
    "    with torch.no_grad():\n",
    "        batch_query = {k: v.to(model.device) for k, v in batch_query.items()}\n",
    "        query_outputs = model(**batch_query)\n",
    "        qr_embs = query_outputs.embeddings\n",
    "    qs.extend(list(torch.unbind(qr_embs.to(\"cuda:0\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(qs))\n",
    "qs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "test_pages_dir = \"/home/linux/yyj/colpali/finetune/mmlm-rag/test_pages\"\n",
    "images = [Image.open(os.path.join(test_pages_dir, name)) for name in os.listdir(test_pages_dir)]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=ListDataset[str](images),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: processor.process_images(x),\n",
    ")\n",
    "ds: List[torch.Tensor] = []\n",
    "for batch_doc in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n",
    "        image_outputs = model(**batch_doc)\n",
    "        img_embs = image_outputs.embeddings\n",
    "    ds.extend(list(torch.unbind(img_embs.to(\"cuda:0\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([1064, 128])\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))\n",
    "print(ds[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "\n",
    "class MilvusColbertRetriever:\n",
    "    def __init__(self, milvus_client, collection_name, dim=128):\n",
    "        # Initialize the retriever with a Milvus client, collection name, and dimensionality of the vector embeddings.\n",
    "        # If the collection exists, load it.\n",
    "        self.collection_name = collection_name\n",
    "        self.client = milvus_client\n",
    "        if self.client.has_collection(collection_name=self.collection_name):\n",
    "            self.client.load_collection(collection_name)\n",
    "        self.dim = dim\n",
    "\n",
    "    def create_collection(self):\n",
    "        # Create a new collection in Milvus for storing embeddings.\n",
    "        # Drop the existing collection if it already exists and define the schema for the collection.\n",
    "        if self.client.has_collection(collection_name=self.collection_name):\n",
    "            self.client.drop_collection(collection_name=self.collection_name)\n",
    "        schema = self.client.create_schema(\n",
    "            auto_id=True,\n",
    "            enable_dynamic_fields=True,\n",
    "        )\n",
    "        schema.add_field(field_name=\"pk\", datatype=DataType.INT64, is_primary=True)\n",
    "        schema.add_field(\n",
    "            field_name=\"vector\", datatype=DataType.FLOAT_VECTOR, dim=self.dim\n",
    "        )\n",
    "        schema.add_field(field_name=\"seq_id\", datatype=DataType.INT16)\n",
    "        schema.add_field(field_name=\"doc_id\", datatype=DataType.INT64)\n",
    "        schema.add_field(field_name=\"doc\", datatype=DataType.VARCHAR, max_length=65535)\n",
    "\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name, schema=schema\n",
    "        )\n",
    "\n",
    "    def create_index(self):\n",
    "        # Create an index on the vector field to enable fast similarity search.\n",
    "        # Releases and drops any existing index before creating a new one with specified parameters.\n",
    "        self.client.release_collection(collection_name=self.collection_name)\n",
    "        self.client.drop_index(\n",
    "            collection_name=self.collection_name, index_name=\"vector\"\n",
    "        )\n",
    "        index_params = self.client.prepare_index_params()\n",
    "        index_params.add_index(\n",
    "            field_name=\"vector\",\n",
    "            index_name=\"vector_index\",\n",
    "            index_type=\"HNSW\",  # or any other index type you want\n",
    "            metric_type=\"IP\",  # or the appropriate metric type\n",
    "            params={\n",
    "                \"M\": 16,\n",
    "                \"efConstruction\": 500,\n",
    "            },  # adjust these parameters as needed\n",
    "        )\n",
    "\n",
    "        self.client.create_index(\n",
    "            collection_name=self.collection_name, index_params=index_params, sync=True\n",
    "        )\n",
    "\n",
    "    def create_scalar_index(self):\n",
    "        # Create a scalar index for the \"doc_id\" field to enable fast lookups by document ID.\n",
    "        self.client.release_collection(collection_name=self.collection_name)\n",
    "\n",
    "        index_params = self.client.prepare_index_params()\n",
    "        index_params.add_index(\n",
    "            field_name=\"doc_id\",\n",
    "            index_name=\"int32_index\",\n",
    "            index_type=\"INVERTED\",  # or any other index type you want\n",
    "        )\n",
    "\n",
    "        self.client.create_index(\n",
    "            collection_name=self.collection_name, index_params=index_params, sync=True\n",
    "        )\n",
    "\n",
    "    def search(self, data, topk):\n",
    "        # Perform a vector search on the collection to find the top-k most similar documents.\n",
    "        # data=query\n",
    "        # \"params\": {} means no extra parameters are passed to the HNSW index algorithm\n",
    "        search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "        # len(results)=22(query.length), each query vector(1*128) has top50 similar doc vector (1*128)\n",
    "        results = self.client.search(\n",
    "            self.collection_name,\n",
    "            data,\n",
    "            limit=int(50),\n",
    "            output_fields=[\"vector\", \"seq_id\", \"doc_id\"],\n",
    "            search_params=search_params,\n",
    "        )\n",
    "        doc_ids = set()\n",
    "        # For each row vector of a query (22 in total), deduplicate the doc_id results of its top 50\n",
    "        for r_id in range(len(results)):\n",
    "            for r in range(len(results[r_id])):\n",
    "                doc_ids.add(results[r_id][r][\"entity\"][\"doc_id\"])\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        def rerank_single_doc(doc_id, data, client, collection_name):\n",
    "            # Rerank a single document by retrieving its embeddings and calculating the similarity with the query.\n",
    "            doc_colbert_vecs = client.query(\n",
    "                collection_name=collection_name,\n",
    "                filter=f\"doc_id in [{doc_id}]\",\n",
    "                output_fields=[\"seq_id\", \"vector\", \"doc\"],\n",
    "                limit=1000,  return the first 1000 row vectors\n",
    "            )\n",
    "            # stack these vectors\n",
    "            doc_vecs = np.vstack(\n",
    "                [doc_colbert_vecs[i][\"vector\"] for i in range(len(doc_colbert_vecs))]\n",
    "            )\n",
    "            # perform ColBERT late interaction for single query-doc_id\n",
    "            score = np.dot(data, doc_vecs.T).max(1).sum()\n",
    "            return (score, doc_id)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:\n",
    "            futures = {\n",
    "                executor.submit(\n",
    "                    rerank_single_doc, doc_id, data, client, self.collection_name\n",
    "                ): doc_id\n",
    "                for doc_id in doc_ids\n",
    "            }\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                score, doc_id = future.result()\n",
    "                scores.append((score, doc_id))\n",
    "        # sort by the score in each tuple in scores\n",
    "        scores.sort(key=lambda x: x[0], reverse=True)\n",
    "        # if the total exceeds topk, take the topk; otherwise, return all\n",
    "        if len(scores) >= topk:\n",
    "            return scores[:topk]\n",
    "        else:\n",
    "            return scores\n",
    "\n",
    "    def insert(self, data):\n",
    "        # Insert ColBERT embeddings and metadata for a document into the collection.\n",
    "        # input is the embedding of an image/pdf page, 1064*128\n",
    "        # data[\"colbert_vecs\"] is a list, 1064*128, each row in the list is a 1*128 torch.tensor\n",
    "        colbert_vecs = [vec for vec in data[\"colbert_vecs\"]]\n",
    "        # seq_length = 1064\n",
    "        seq_length = len(colbert_vecs)\n",
    "        # generate the same doc_id and docs file path for 1064 row vectors\n",
    "        # repeat data[\"doc_id\"] for seq_length times, [doc_id, ..., doc_id];\n",
    "        doc_ids = [data[\"doc_id\"] for i in range(seq_length)]\n",
    "        # seq_ids = [0,1,2,...,1063]\n",
    "        seq_ids = list(range(seq_length))\n",
    "        # repeat data[\"filepath\"] seq_length times\n",
    "        docs = [data[\"filepath\"] for i in range(seq_length)]\n",
    "\n",
    "        # Insert the data as multiple vectors (one for each sequence) along with the corresponding metadata.\n",
    "        self.client.insert(\n",
    "            self.collection_name,\n",
    "            [\n",
    "                {\n",
    "                    \"vector\": colbert_vecs[i],\n",
    "                    \"seq_id\": seq_ids[i],\n",
    "                    \"doc_id\": doc_ids[i],\n",
    "                    \"doc\": docs[i],\n",
    "                }\n",
    "                for i in range(seq_length)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "client = MilvusClient(uri=\"http://localhost:19530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MilvusColbertRetriever(collection_name=\"colqwen_test\", milvus_client=client)\n",
    "# retriever.create_collection()\n",
    "# retriever.create_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.compression.token_pooling import HierarchicalTokenPooler\n",
    "\n",
    "# Define the pooler with the desired level of compression\n",
    "pooler = HierarchicalTokenPooler()\n",
    "\n",
    "# Pool the embeddings, returun_dict default as False, only return pooled_embeddings\n",
    "outputs = pooler.pool_embeddings(ds, pool_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [os.path.join(test_pages_dir, name) for name in os.listdir(test_pages_dir)]\n",
    "for i in range(len(filepaths)):\n",
    "    data = {\n",
    "        \"colbert_vecs\": outputs[i].float().cpu().numpy(),\n",
    "        \"doc_id\": i,\n",
    "        \"filepath\": filepaths[i],\n",
    "    }\n",
    "    retriever.insert(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/linux/yyj/colpali/finetune/mmlm-rag/test_pages/test_page_001.png\n",
      "/home/linux/yyj/colpali/finetune/mmlm-rag/test_pages/test_page_001.png\n"
     ]
    }
   ],
   "source": [
    "for query in qs:\n",
    "    # query: 22*128\n",
    "    query = query.float().cpu().numpy()\n",
    "    result = retriever.search(query, topk=1)\n",
    "    print(filepaths[result[0][1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
