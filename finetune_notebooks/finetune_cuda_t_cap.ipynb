{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/envs/colpali/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 1103 examples [00:00, 40758.71 examples/s]\n",
      "Map: 100%|██████████| 1103/1103 [00:00<00:00, 9142.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "# load json file\n",
    "json_data_path = \"/home/linux/yyj/colpali/finetune/img_cap_pairs_t.json\"\n",
    "ds = load_dataset(\"json\", data_files=json_data_path, split=\"train\")\n",
    "\n",
    "# load images\n",
    "image_dir = \"/home/linux/yyj/colpali/finetune/pdf2images\"\n",
    "def load_image(example, image_dir):\n",
    "    full_path = os.path.join(image_dir, example[\"image_path\"])\n",
    "    example[\"image\"] = Image.open(full_path)\n",
    "    return example\n",
    "\n",
    "ds = ds.map(partial(load_image, image_dir=image_dir))\n",
    "\n",
    "# split dataset\n",
    "ds = ds.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pynvml not found. GPU stats will not be printed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    ColPaliForRetrieval, ColPaliProcessor, EarlyStoppingCallback\n",
    "from colpali_engine.loss import ColbertPairwiseCELoss\n",
    "from colpali_engine.trainer.contrastive_trainer import ContrastiveTrainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model_dir = \"/home/linux/yyj/colpali/finetune/colpali-v1.2-hf\"\n",
    "model = ColPaliForRetrieval.from_pretrained(\n",
    "    model_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"cuda:0\",\n",
    ").eval()\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=8,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=['down_proj','o_proj','k_proj','q_proj','gate_proj','up_proj','v_proj'],\n",
    "        init_lora_weights=\"gaussian\"\n",
    "    )\n",
    "lora_config.inference_mode = False\n",
    "model = get_peft_model(model, lora_config)\n",
    "processor = ColPaliProcessor.from_pretrained(model_dir)\n",
    "\n",
    "def collate_fn(examples):\n",
    "    texts = []\n",
    "    images = []\n",
    "\n",
    "    for example in examples:\n",
    "\n",
    "        texts.append(example[\"caption\"])\n",
    "        images.append(example[\"image\"].convert(\"RGB\"))\n",
    "\n",
    "    batch_images = processor(images=images, return_tensors=\"pt\").to(model.device)\n",
    "    batch_queries = processor(text=texts, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    return (batch_queries, batch_images)\n",
    "\n",
    "\n",
    "class ContrastiveTrainer(Trainer):\n",
    "    def __init__(self, loss_func, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_func = loss_func\n",
    "\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch=4, return_outputs=False):\n",
    "        query_inputs, doc_inputs = inputs\n",
    "        query_outputs = model(**query_inputs)\n",
    "        doc_outputs = model(**doc_inputs)\n",
    "        loss = self.loss_func(query_outputs.embeddings, doc_outputs.embeddings)\n",
    "        return (loss, (query_outputs, doc_outputs)) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only=True, ignore_keys=None):\n",
    "        query_inputs, doc_inputs = inputs # unpack from data collator\n",
    "        with torch.no_grad():\n",
    "            query_outputs = model(**query_inputs)\n",
    "            doc_outputs = model(**doc_inputs)\n",
    "\n",
    "            loss = self.loss_func(query_outputs.embeddings, doc_outputs.embeddings)\n",
    "            \n",
    "            return loss, None, None if prediction_loss_only else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./colpali_city_0529\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=False,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",    \n",
    "    eval_steps=10,\n",
    "    warmup_steps=20,\n",
    "    learning_rate=5e-5,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"tensorboard\",\n",
    "    dataloader_pin_memory=False,\n",
    "    load_best_model_at_end=True,      \n",
    "    metric_for_best_model=\"loss\",      \n",
    "    greater_is_better=False   \n",
    ")\n",
    "\n",
    "\n",
    "trainer = ContrastiveTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    args=training_args,\n",
    "    loss_func=ColbertPairwiseCELoss(),\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.args.remove_unused_columns = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/180 25:43 < 20:59, 0.06 it/s, Epoch 2/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>15.828100</td>\n",
       "      <td>1.261523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.547500</td>\n",
       "      <td>0.391962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.243903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.160004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.140658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.103096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>0.128103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.155246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.150843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=1.9678859949111938, metrics={'train_runtime': 1554.1382, 'train_samples_per_second': 2.838, 'train_steps_per_second': 0.116, 'total_flos': 0.0, 'train_loss': 1.9678859949111938, 'epoch': 2.761904761904762})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"/home/linux/yyj/colpali/finetune/wiky_city_zh_0528\")  # 包括模型和 tokenizer 等信息\n",
    "processor.save_pretrained(\"/home/linux/yyj/colpali/finetune/wiky_city_zh_0528\")  # 保存预处理器，如 tokenizer + image processor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colpali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
